{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directories and file paths\n",
    "mriqc_dir = \"ds004636/derivatives/mriqc\"\n",
    "csv_file = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "all_included_file = \"all_included/all_included.txt\"\n",
    "mriqc_failed_file = \"mriqc_failed/mriqc_failed.txt\"\n",
    "\n",
    "# Task names to filter\n",
    "TASKS = {\"ANT\", \"CCTHot\", \"WATT3\", \"stopSignal\", \"twoByTwo\", \"DPX\", \"discountFix\", \"motorSelectiveStop\", \"stroop\", \"surveyMedley\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse filenames\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    subject = parts[0].replace(\"sub-\", \"\")\n",
    "    task = next((t for t in TASKS if t in filename), None)\n",
    "    return subject, task\n",
    "\n",
    "def extract_metrics(html_path, metrics):\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    data = {}\n",
    "    other_section = soup.find(id=\"other\")\n",
    "    if not other_section:\n",
    "        print(f\" other table not found for {html_path}\")\n",
    "        return data  # Return empty if \"Other\" section is not found\n",
    "    \n",
    "    table = other_section.find_next(\"table\", {\"id\": \"iqms-table\"})\n",
    "    if not table:\n",
    "        print(f\"iqms table not found for {html_path}\")\n",
    "        return data  # Return empty if table is not found\n",
    "    \n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) == 2:\n",
    "            metric_name = cells[0].text.strip()\n",
    "            value = cells[1].text.strip()\n",
    "        elif len(cells) == 3:\n",
    "            # print(\"idk\")\n",
    "            metric_name = f\"{cells[0].text.strip()}_{cells[1].text.strip()}\"\n",
    "            value = cells[2].text.strip()\n",
    "        else:\n",
    "            # print(\"else\")\n",
    "            continue\n",
    "        \n",
    "        if metric_name in metrics:\n",
    "            try:\n",
    "                data[metric_name] = float(value)\n",
    "            except ValueError:\n",
    "                data[metric_name] = value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Organize data into JSON\n",
    "quality_data = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "\n",
    "# Read metric names from CSV\n",
    "metrics = set()\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metric_name = row['Metric'] #changed this later, didn't check, might have problem!!!\n",
    "        metrics.add(metric_name)\n",
    "        \n",
    "# Process both files\n",
    "for category, txt_file in [(\"mriqc_failed\", mriqc_failed_file), (\"all_included\", all_included_file)]:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        filenames = [line.strip() for line in f]\n",
    "\n",
    "    for filename in filenames:\n",
    "        html_path = os.path.join(mriqc_dir, filename)\n",
    "        if os.path.isfile(html_path):\n",
    "            subject, task = parse_filename(filename)\n",
    "            if task:\n",
    "                if task not in quality_data[category]:\n",
    "                    quality_data[category][task] = {}\n",
    "                if subject not in quality_data[category][task]:\n",
    "                    quality_data[category][task][subject] = {}\n",
    "                quality_data[category][task][subject] = extract_metrics(html_path, metrics)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"quality_metrics/quality_metrics.json\", \"w\") as f:\n",
    "    json.dump(quality_data, f, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(input_json, output_json):\n",
    "    with open(input_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    reformatted = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "    \n",
    "    for category in [\"mriqc_failed\", \"all_included\"]:\n",
    "        for task, subjects in data.get(category, {}).items():\n",
    "            if task not in reformatted[category]:\n",
    "                reformatted[category][task] = {}\n",
    "            \n",
    "            for subject, metrics in subjects.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric not in reformatted[category][task]:\n",
    "                        reformatted[category][task][metric] = {}\n",
    "                    \n",
    "                    reformatted[category][task][metric][subject] = value\n",
    "    \n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(reformatted, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_json = \"quality_metrics/quality_metrics.json\"\n",
    "output_json = \"quality_metrics/quality_metrics_reformatted.json\"\n",
    "metrics_csv = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "output_dir = \"quality_metrics/plots\"\n",
    "\n",
    "# Run functions\n",
    "# reformat_json(input_json, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_task_metric(task, metric, data, thresholds, save_dir=\"quality_metrics/plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    subjects = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract data for both \"mriqc_failed\" and \"all_included\"\n",
    "    for category in [\"all_included\",\"mriqc_failed\"]:\n",
    "        if task in data[category] and metric in data[category][task]:\n",
    "            for subject, value in data[category][task][metric].items():\n",
    "                subjects.append(subject)\n",
    "                values.append(value)\n",
    "                categories.append(category)  # Keep track of whether it's \"mriqc_failed\" or \"all_included\"\n",
    "    \n",
    "    # Z-normalize values using Low, High, and Median from thresholds\n",
    "    if metric in thresholds:\n",
    "        (low, high, median) = thresholds[metric]\n",
    "        std_dev = (high - low) / 2  # Approximate standard deviation\n",
    "        values = [(v - median) / std_dev for v in values]\n",
    "\n",
    "    # Assign colors (red if outside range, green if inside)\n",
    "    for value in values:\n",
    "        if -1 <= value <= 1:  # Within expected range\n",
    "            colors.append(\"green\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    \n",
    "    # Separate \"mriqc_failed\" from \"all_included\" in the plot\n",
    "    non_failed_count = sum(1 for cat in categories if cat == \"all_included\")\n",
    "    \n",
    "    fig_height = max(6, len(subjects) * 0.3)  # Store the calculated height\n",
    "\n",
    "    # Increase figure height\n",
    "    fig, ax = plt.subplots(figsize=(8, fig_height))\n",
    "    \n",
    "    ax.scatter(values, range(len(subjects)), c=colors, edgecolors=\"black\", s=60)\n",
    "    \n",
    "    # Add a horizontal separation line between failed and included\n",
    "    if non_failed_count > 0:\n",
    "        ax.axhline(y=non_failed_count - 0.5, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    # Set y-axis labels (subjects)\n",
    "    ax.set_yticks(range(len(subjects)))\n",
    "    ax.set_yticklabels(subjects)\n",
    "    \n",
    "    # Add plot title and labels\n",
    "    plt.title(f\"{task} - {metric} Plot\", fontsize=14, pad=20)\n",
    "    plt.xlabel(\"Z-Normalized Value\", fontsize=12)\n",
    "    plt.ylabel(\"Subjects\", fontsize=12)\n",
    "    \n",
    "    # Draw shaded gray region for acceptable range (-1 to 1)\n",
    "    ax.axvspan(-1, 1, color=\"gray\", alpha=0.2)\n",
    "    \n",
    "    # Ensure x-axis ticks are visible\n",
    "    plt.xticks(range(int(min(values)) - 1, int(max(values)) + 2))\n",
    "    \n",
    "    # Adjust margins\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{task}-{metric}.png\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = dict()\n",
    "with open(metrics_csv, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # Read CSV as dictionary\n",
    "    for row in reader:\n",
    "        metric = row[\"Metric\"]  # Get the metric name\n",
    "        low, high, median = float(row[\"Low\"]), float(row[\"High\"]), float(row[\"Median\"])  # Convert to floats\n",
    "        thresholds[metric] = (low, high, median)\n",
    "\n",
    "\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    for task in TASKS:\n",
    "        for metric in list(thresholds.keys()):\n",
    "            plot_task_metric(task, metric, data, thresholds, save_dir=\"quality_metrics/plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = dict()\n",
    "with open(metrics_csv, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # Read CSV as dictionary\n",
    "    for row in reader:\n",
    "        metric = row[\"Metric\"]  # Get the metric name\n",
    "        low, high, median = float(row[\"Low\"]), float(row[\"High\"]), float(row[\"Median\"])  # Convert to floats\n",
    "        thresholds[metric] = (low, high, median)\n",
    "\n",
    "\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    plot_task_metric(\"ANT\", \"dvars_vstd\", data, thresholds, save_dir=\"quality_metrics/plots\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108b6a53701acb9a927e75116c1592fea8c9877210136ac52aa69b79290702dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
