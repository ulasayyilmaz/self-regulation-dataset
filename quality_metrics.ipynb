{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directories and file paths\n",
    "mriqc_dir = \"ds004636/derivatives/mriqc\"\n",
    "csv_file = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "all_included_file = \"all_included/all_included.txt\"\n",
    "mriqc_failed_file = \"mriqc_failed/mriqc_failed.txt\"\n",
    "\n",
    "# Task names to filter\n",
    "TASKS = {\"ANT\", \"CCTHot\", \"WATT3\", \"stopSignal\", \"twoByTwo\", \"DPX\", \"discountFix\", \"motorSelectiveStop\", \"stroop\", \"surveyMedley\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse filenames\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    subject = parts[0].replace(\"sub-\", \"\")\n",
    "    task = next((t for t in TASKS if t in filename), None)\n",
    "    return subject, task\n",
    "\n",
    "def extract_metrics(html_path, metrics):\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    data = {}\n",
    "    other_section = soup.find(id=\"other\")\n",
    "    if not other_section:\n",
    "        print(f\" other table not found for {html_path}\")\n",
    "        return data  # Return empty if \"Other\" section is not found\n",
    "    \n",
    "    table = other_section.find_next(\"table\", {\"id\": \"iqms-table\"})\n",
    "    if not table:\n",
    "        print(f\"iqms table not found for {html_path}\")\n",
    "        return data  # Return empty if table is not found\n",
    "    \n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) == 2:\n",
    "            metric_name = cells[0].text.strip()\n",
    "            value = cells[1].text.strip()\n",
    "        elif len(cells) == 3:\n",
    "            # print(\"idk\")\n",
    "            metric_name = f\"{cells[0].text.strip()}_{cells[1].text.strip()}\"\n",
    "            value = cells[2].text.strip()\n",
    "        else:\n",
    "            # print(\"else\")\n",
    "            continue\n",
    "        \n",
    "        if metric_name in metrics:\n",
    "            try:\n",
    "                data[metric_name] = float(value)\n",
    "            except ValueError:\n",
    "                data[metric_name] = value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Organize data into JSON\n",
    "quality_data = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "\n",
    "# Read metric names from CSV\n",
    "metrics = set()\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metric_name = row['Metric'] #changed this later, didn't check, might have problem!!!\n",
    "        metrics.add(metric_name)\n",
    "        \n",
    "# Process both files\n",
    "for category, txt_file in [(\"mriqc_failed\", mriqc_failed_file), (\"all_included\", all_included_file)]:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        filenames = [line.strip() for line in f]\n",
    "\n",
    "    for filename in filenames:\n",
    "        html_path = os.path.join(mriqc_dir, filename)\n",
    "        if os.path.isfile(html_path):\n",
    "            subject, task = parse_filename(filename)\n",
    "            if task:\n",
    "                if task not in quality_data[category]:\n",
    "                    quality_data[category][task] = {}\n",
    "                if subject not in quality_data[category][task]:\n",
    "                    quality_data[category][task][subject] = {}\n",
    "                quality_data[category][task][subject] = extract_metrics(html_path, metrics)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"quality_metrics/quality_metrics.json\", \"w\") as f:\n",
    "    json.dump(quality_data, f, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(input_json, output_json):\n",
    "    with open(input_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    reformatted = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "    \n",
    "    for category in [\"mriqc_failed\", \"all_included\"]:\n",
    "        for task, subjects in data.get(category, {}).items():\n",
    "            if task not in reformatted[category]:\n",
    "                reformatted[category][task] = {}\n",
    "            \n",
    "            for subject, metrics in subjects.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric not in reformatted[category][task]:\n",
    "                        reformatted[category][task][metric] = {}\n",
    "                    \n",
    "                    reformatted[category][task][metric][subject] = value\n",
    "    \n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(reformatted, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_json = \"quality_metrics/quality_metrics.json\"\n",
    "output_json = \"quality_metrics/quality_metrics_reformatted.json\"\n",
    "metrics_csv = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "output_dir = \"quality_metrics/plots\"\n",
    "\n",
    "# Run functions\n",
    "# reformat_json(input_json, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_task_metric(task, metric, data, thresholds, save_dir=\"quality_metrics/plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    subjects = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract data for both \"mriqc_failed\" and \"all_included\"\n",
    "    for category in [\"all_included\",\"mriqc_failed\"]:\n",
    "        if task in data[category] and metric in data[category][task]:\n",
    "            for subject, value in data[category][task][metric].items():\n",
    "                subjects.append(subject)\n",
    "                values.append(value)\n",
    "                categories.append(category)  # Keep track of whether it's \"mriqc_failed\" or \"all_included\"\n",
    "    \n",
    "    # Z-normalize values using Low, High, and Median from thresholds\n",
    "    if metric in thresholds:\n",
    "        (low, high, median) = thresholds[metric]\n",
    "        std_dev = (high - low) / 2  # Approximate standard deviation\n",
    "        values = [(v - median) / std_dev for v in values]\n",
    "\n",
    "    # Assign colors (red if outside range, green if inside)\n",
    "    for value in values:\n",
    "        if -1 <= value <= 1:  # Within expected range\n",
    "            colors.append(\"green\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    \n",
    "    # Separate \"mriqc_failed\" from \"all_included\" in the plot\n",
    "    non_failed_count = sum(1 for cat in categories if cat == \"all_included\")\n",
    "    \n",
    "    fig_height = max(6, len(subjects) * 0.3)  # Store the calculated height\n",
    "\n",
    "    # Increase figure height\n",
    "    fig, ax = plt.subplots(figsize=(8, fig_height))\n",
    "    \n",
    "    ax.scatter(values, range(len(subjects)), c=colors, edgecolors=\"black\", s=60)\n",
    "    \n",
    "    # Add a horizontal separation line between failed and included\n",
    "    if non_failed_count > 0:\n",
    "        ax.axhline(y=non_failed_count - 0.5, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "    # Set y-axis labels (subjects)\n",
    "    ax.set_yticks(range(len(subjects)))\n",
    "    ax.set_yticklabels(subjects)\n",
    "    \n",
    "    # Add plot title and labels\n",
    "    plt.title(f\"{task} - {metric} Plot\", fontsize=14, pad=20)\n",
    "    plt.xlabel(\"Z-Normalized Value\", fontsize=12)\n",
    "    plt.ylabel(\"Subjects\", fontsize=12)\n",
    "    \n",
    "    # Draw shaded gray region for acceptable range (-1 to 1)\n",
    "    ax.axvspan(-1, 1, color=\"gray\", alpha=0.2)\n",
    "    \n",
    "    # Ensure x-axis ticks are visible\n",
    "    plt.xticks(range(int(min(values)) - 1, int(max(values)) + 2))\n",
    "    \n",
    "    # Adjust margins\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{task}-{metric}.png\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = dict()\n",
    "with open(metrics_csv, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # Read CSV as dictionary\n",
    "    for row in reader:\n",
    "        metric = row[\"Metric\"]  # Get the metric name\n",
    "        low, high, median = float(row[\"Low\"]), float(row[\"High\"]), float(row[\"Median\"])  # Convert to floats\n",
    "        thresholds[metric] = (low, high, median)\n",
    "\n",
    "\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    for task in TASKS:\n",
    "        for metric in list(thresholds.keys()):\n",
    "            plot_task_metric(task, metric, data, thresholds, save_dir=\"quality_metrics/plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = dict()\n",
    "with open(metrics_csv, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # Read CSV as dictionary\n",
    "    for row in reader:\n",
    "        metric = row[\"Metric\"]  # Get the metric name\n",
    "        low, high, median = float(row[\"Low\"]), float(row[\"High\"]), float(row[\"Median\"])  # Convert to floats\n",
    "        thresholds[metric] = (low, high, median)\n",
    "\n",
    "\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    plot_task_metric(\"ANT\", \"dvars_vstd\", data, thresholds, save_dir=\"quality_metrics/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Set path to MRIQC outputs \n",
    "mriqc_path = 'ds004636/derivatives/mriqc/sub-*/ses-*/*/'\n",
    "\n",
    "def get_mriqc_summary(mriqc_path, image_type, metrics_to_plot):\n",
    "    json_files = glob.glob(os.path.join(mriqc_path, f'*{image_type}*.json'))\n",
    "    all_metrics = defaultdict(list)\n",
    "    for jfile in json_files:\n",
    "        with open(jfile, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for key, value in data.items():\n",
    "                if key in metrics_to_plot and isinstance(value, (float, int)):\n",
    "                    all_metrics[key].append(value)\n",
    "    return all_metrics\n",
    "\n",
    "    \n",
    "def plot_summary_IQMs(mriqc_path, image_type, metrics_to_plot):\n",
    "    summary = get_mriqc_summary(mriqc_path, image_type, metrics_to_plot)\n",
    "    # Setting up the figure and axes\n",
    "    num_metrics = len(metrics_to_plot)\n",
    "    rows = (num_metrics + 1) // 3\n",
    "    fig, axs = plt.subplots(rows, 3, figsize=(15, 5*rows))\n",
    "\n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        ax = axs[idx // 3, idx % 3]\n",
    "        values = summary[metric]\n",
    "        ax.hist(values, bins=30, alpha=0.75)\n",
    "        ax.set_xlabel(metric)\n",
    "        ax.set_ylabel('Number of scans')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Remove any unused subplots (if an odd number of metrics)\n",
    "    if num_metrics % 3 != 0:\n",
    "        axs[-1, -1].axis('off')\n",
    "\n",
    "    # Add a big title to the entire figure\n",
    "    fig.suptitle(image_type, fontsize=20, y=0.92)\n",
    "    if image_type == 'task':\n",
    "        fig.suptitle('BOLD fMRI', fontsize=20, y=0.92)\n",
    "    # Adjust the spacing between the subplots\n",
    "    plt.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stats(mriqc_path, image_type, metrics_to_plot):\n",
    "    summary = get_mriqc_summary(mriqc_path, image_type, metrics_to_plot)\n",
    "    for metric in metrics_to_plot:\n",
    "        values = summary[metric]\n",
    "        print(f'{metric}: {np.mean(values):.2f} +/- {np.std(values):.2f}')\n",
    "        print(f'{metric}: {np.min(values):.2f} - {np.max(values):.2f}')\n",
    "\n",
    "def get_motion_exclusions(mriqc_path, image_type):\n",
    "    json_files = glob.glob(os.path.join(mriqc_path, f'*{image_type}*.json'))\n",
    "    motion_exclusions = []\n",
    "    for jfile in json_files:\n",
    "        with open(jfile, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            if data['fd_mean'] > 0.5:\n",
    "                motion_exclusions.append(jfile)\n",
    "            if data['dvars_std'] > 1.2:\n",
    "                motion_exclusions.append(jfile)\n",
    "    motion_exclusions = list(set(motion_exclusions))\n",
    "    print(f'Task: {image_type}')\n",
    "    print(f'Number of motion exclusions: {len(motion_exclusions)}')\n",
    "    return motion_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qi_1: nan +/- nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulasayyilmaz/fsl/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/ulasayyilmaz/fsl/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/ulasayyilmaz/fsl/lib/python3.11/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/ulasayyilmaz/fsl/lib/python3.11/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/Users/ulasayyilmaz/fsl/lib/python3.11/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics_to_plot \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqi_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_gm_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnr_total\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mget_summary_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmriqc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT1w\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_to_plot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plot_summary_IQMs(mriqc_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT1w\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics_to_plot)\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_summary_stats\u001b[0;34m(mriqc_path, image_type, metrics_to_plot)\u001b[0m\n\u001b[1;32m      4\u001b[0m values \u001b[38;5;241m=\u001b[39m summary[metric]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmax(values)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/fsl/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2953\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2836\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   2837\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2838\u001b[0m         where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2839\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2840\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[1;32m   2952\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2953\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2954\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/fsl/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "metrics_to_plot = ['qi_1', 'cnr', 'efc', 'fber', 'summary_gm_mean', 'snr_total']\n",
    "get_summary_stats(mriqc_path, 'T1w', metrics_to_plot)\n",
    "plot_summary_IQMs(mriqc_path, 'T1w', metrics_to_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108b6a53701acb9a927e75116c1592fea8c9877210136ac52aa69b79290702dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
