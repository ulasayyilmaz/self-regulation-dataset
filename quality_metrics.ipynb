{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directories and file paths\n",
    "mriqc_dir = \"ds004636/derivatives/mriqc\"\n",
    "csv_file = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "all_included_file = \"all_included/all_included.txt\"\n",
    "mriqc_failed_file = \"mriqc_failed/mriqc_failed.txt\"\n",
    "\n",
    "# Task names to filter\n",
    "TASKS = {\"ANT\", \"CCTHot\", \"WATT3\", \"stopSignal\", \"twoByTwo\", \"DPX\", \"discountFix\", \"motorSelectiveStop\", \"stroop\", \"surveyMedley\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse filenames\n",
    "def parse_filename(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    subject = parts[0].replace(\"sub-\", \"\")\n",
    "    task = next((t for t in TASKS if t in filename), None)\n",
    "    return subject, task\n",
    "\n",
    "def extract_metrics(html_path, metrics):\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    data = {}\n",
    "    other_section = soup.find(id=\"other\")\n",
    "    if not other_section:\n",
    "        print(f\" other table not found for {html_path}\")\n",
    "        return data  # Return empty if \"Other\" section is not found\n",
    "    \n",
    "    table = other_section.find_next(\"table\", {\"id\": \"iqms-table\"})\n",
    "    if not table:\n",
    "        print(f\"iqms table not found for {html_path}\")\n",
    "        return data  # Return empty if table is not found\n",
    "    \n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) == 2:\n",
    "            metric_name = cells[0].text.strip()\n",
    "            value = cells[1].text.strip()\n",
    "        elif len(cells) == 3:\n",
    "            # print(\"idk\")\n",
    "            metric_name = f\"{cells[0].text.strip()}_{cells[1].text.strip()}\"\n",
    "            value = cells[2].text.strip()\n",
    "        else:\n",
    "            # print(\"else\")\n",
    "            continue\n",
    "        \n",
    "        if metric_name in metrics:\n",
    "            try:\n",
    "                data[metric_name] = float(value)\n",
    "            except ValueError:\n",
    "                data[metric_name] = value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Organize data into JSON\n",
    "quality_data = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "\n",
    "# Read metric names from CSV\n",
    "metrics = set()\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metric_name = row['Metric'] #changed this later, didn't check, might have problem!!!\n",
    "        metrics.add(metric_name)\n",
    "        \n",
    "# Process both files\n",
    "for category, txt_file in [(\"mriqc_failed\", mriqc_failed_file), (\"all_included\", all_included_file)]:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        filenames = [line.strip() for line in f]\n",
    "\n",
    "    for filename in filenames:\n",
    "        html_path = os.path.join(mriqc_dir, filename)\n",
    "        if os.path.isfile(html_path):\n",
    "            subject, task = parse_filename(filename)\n",
    "            if task:\n",
    "                if task not in quality_data[category]:\n",
    "                    quality_data[category][task] = {}\n",
    "                if subject not in quality_data[category][task]:\n",
    "                    quality_data[category][task][subject] = {}\n",
    "                quality_data[category][task][subject] = extract_metrics(html_path, metrics)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"quality_metrics/quality_metrics.json\", \"w\") as f:\n",
    "    json.dump(quality_data, f, indent=4)\n",
    "\n",
    "print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(input_json, output_json):\n",
    "    with open(input_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    reformatted = {\"mriqc_failed\": {}, \"all_included\": {}}\n",
    "    \n",
    "    for category in [\"mriqc_failed\", \"all_included\"]:\n",
    "        for task, subjects in data.get(category, {}).items():\n",
    "            if task not in reformatted[category]:\n",
    "                reformatted[category][task] = {}\n",
    "            \n",
    "            for subject, metrics in subjects.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric not in reformatted[category][task]:\n",
    "                        reformatted[category][task][metric] = {}\n",
    "                    \n",
    "                    reformatted[category][task][metric][subject] = value\n",
    "    \n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(reformatted, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_json = \"quality_metrics/quality_metrics.json\"\n",
    "output_json = \"quality_metrics/quality_metrics_reformatted.json\"\n",
    "metrics_csv = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "output_dir = \"quality_metrics/plots\"\n",
    "\n",
    "# Run functions\n",
    "# reformat_json(input_json, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_task_metric(json_file, metrics_csv, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    metrics_df = pd.read_csv(metrics_csv)\n",
    "    metric_bounds = {row[\"Metric\"]: (row[\"Low\"], row[\"High\"], row[\"Median\"]) for _, row in metrics_df.iterrows()}\n",
    "     \n",
    "    for category in [\"mriqc_failed\", \"all_included\"]:\n",
    "        for task, metrics in data.get(category, {}).items():\n",
    "            for metric, subjects in metrics.items():\n",
    "                if metric not in metric_bounds:\n",
    "                    continue  # Skip if metric info is missing\n",
    "                \n",
    "                low, high, median = metric_bounds[metric]\n",
    "                values = [(subj, (val - median) / ((high - low) / 2)) for subj, val in subjects.items()]\n",
    "                \n",
    "                if not values:\n",
    "                    continue  # Skip empty lists\n",
    "                \n",
    "                values.sort(key=lambda x: x[0])  # Sort by subject ID\n",
    "                subjects_list, z_scores = zip(*values)\n",
    "                \n",
    "                colors = [\"green\" if low <= val * ((high - low) / 2) + median <= high else \"red\" for val in z_scores]\n",
    "                \n",
    "                plt.figure(figsize=(8, len(subjects_list) * 0.3))\n",
    "                plt.scatter(z_scores, range(len(subjects_list)), c=colors, edgecolors='black')\n",
    "                plt.axvspan(-1, 1, color='gray', alpha=0.3)  # Shade normal range\n",
    "                \n",
    "                plt.yticks(range(len(subjects_list)), subjects_list)\n",
    "                plt.axhline(y=len(data.get(\"mriqc_failed\", {}).get(task, {}).get(metric, {})), color='black', linestyle='--')\n",
    "                plt.xlabel(\"Z-Normalized Value\")\n",
    "                plt.ylabel(\"Subjects\")\n",
    "                plt.title(f\"{task}-{metric} Plot\")\n",
    "                \n",
    "                plt.savefig(os.path.join(output_dir, f\"{task}-{metric} Plot.png\"))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_task_metric(output_json, metrics_csv, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "108b6a53701acb9a927e75116c1592fea8c9877210136ac52aa69b79290702dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
