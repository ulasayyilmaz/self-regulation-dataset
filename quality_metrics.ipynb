{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directories and file paths\n",
    "mriqc_failed_dir = \"ds004636/derivatives/mriqc_failed\"\n",
    "mriqc_passed_dir = \"ds004636/derivatives/mriqc_passed\"\n",
    "\n",
    "csv_file = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "mriqc_passed_txt = \"metadata/mriqc_passed/mriqc_passed_fullname.txt\"\n",
    "mriqc_failed_txt = \"metadata/mriqc_failed/mriqc_failed_fullname.txt\"\n",
    "\n",
    "# Task names to filter\n",
    "TASKS = {\"ANT\", \"CCTHot\", \"WATT3\", \"StopSignal\", \"TwoByTwo\", \"DPX\", \"DiscountFix\", \"MotorSelectiveStop\", \"Stroop\", \"SurveyMedley\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "        # takes in file names from mriqc_failed.txt or mriqc_passed.txt\n",
    "        # and returns subject and task\n",
    "\n",
    "    Args:\n",
    "        filename (string): _description_\n",
    "\n",
    "    Returns:\n",
    "        subject (string)\n",
    "        task (str)\n",
    "    \"\"\"\n",
    "    parts = filename.split(\"_\")\n",
    "    subject = parts[0].replace(\"sub-\", \"\")\n",
    "    task = next((t for t in TASKS if t in filename), None)\n",
    "    return subject, task\n",
    "\n",
    "\n",
    "def extract_metrics(html_path, metrics):\n",
    "    \"\"\"given the full html name, and metrics (found in BOLD_quality_metrics.csv)\n",
    "    extract relevant information from the html files, populates the data dictionary with \n",
    "    key(metric) and value(metric value) pairs\n",
    "\n",
    "    Args:\n",
    "        html_path (_type_): _description_\n",
    "        metrics (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        data: a dictionary with keys metric names and values: metric values e\n",
    "    \"\"\"\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    data = {}\n",
    "\n",
    "    # relevant metric key and values are under \"other\" on html files\n",
    "    other_section = soup.find(id=\"other\")\n",
    "    if not other_section:\n",
    "        print(f\" other table not found for {html_path}\")\n",
    "        return data  # Return empty if \"Other\" section is not found\n",
    "    \n",
    "    # in the other section, get the table with id \"iqms-table\" which is where ketric key-value pairs are listed\n",
    "    table = other_section.find_next(\"table\", {\"id\": \"iqms-table\"})\n",
    "    if not table:\n",
    "        print(f\"iqms table not found for {html_path}\")\n",
    "        return data  # Return empty if table is not found\n",
    "    \n",
    "    # scrape the info, assign them to metric_name and value\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) == 2:\n",
    "            metric_name = cells[0].text.strip()\n",
    "            value = cells[1].text.strip()\n",
    "        elif len(cells) == 3:\n",
    "            # for when metric has two parts seperated by \"_\"\n",
    "            metric_name = f\"{cells[0].text.strip()}_{cells[1].text.strip()}\"\n",
    "            value = cells[2].text.strip()\n",
    "        else:\n",
    "            # print(\"else\")\n",
    "            continue\n",
    "        \n",
    "        # add everything to data dictionary\n",
    "        if metric_name in metrics:\n",
    "            try:\n",
    "                data[metric_name] = float(value)\n",
    "            except ValueError:\n",
    "                data[metric_name] = value\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Organize data into JSON\n",
    "# quality_data = {\"mriqc_failed\": {}, \"mriqc_passed\": {}}\n",
    "\n",
    "# Read metric names from CSV (BOLD_quality_metrics)\n",
    "metrics = set()\n",
    "with open(csv_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metric_name = row['Metric'] #changed this later, didn't check, might have problem!!!\n",
    "        metrics.add(metric_name)\n",
    "        \n",
    "# # Process both mriqc_failed_txt and mriqc_passed_txt files.\n",
    "# for category, txt_file in [(\"mriqc_failed\", mriqc_failed_txt), (\"mriqc_passed\", mriqc_passed_txt)]:\n",
    "#     with open(txt_file, \"r\") as f:\n",
    "\n",
    "#         # filenames is a list of all full html file names in failed and passed combined\n",
    "#         filenames = [line.strip() for line in f]\n",
    "\n",
    "#     # sets mriqc_dir as the current directory\n",
    "#     if category == \"mriqc_failed\": \n",
    "#         mriqc_dir = mriqc_failed_dir\n",
    "#     else:\n",
    "#         mriqc_dir = mriqc_passed_dir\n",
    "\n",
    "#     # for each html in mriqc_passed or mriqc_failed, get the metrics using extract_metrics function \n",
    "#     for filename in filenames:\n",
    "#         html_path = os.path.join(mriqc_dir, filename)\n",
    "#         if os.path.isfile(html_path):\n",
    "#             subject, task = parse_filename(filename)\n",
    "#             if task:\n",
    "#                 if task not in quality_data[category]:\n",
    "#                     quality_data[category][task] = {}\n",
    "#                 if subject not in quality_data[category][task]:\n",
    "#                     quality_data[category][task][subject] = {}\n",
    "#                 quality_data[category][task][subject] = extract_metrics(html_path, metrics)\n",
    "#         else:\n",
    "#             print(f\"not a path name {filename}\")\n",
    "    \n",
    "# # Save quality_data to json file.\n",
    "# with open(\"quality_metrics/quality_metrics_all.json\", \"w\") as f:\n",
    "#     json.dump(quality_data, f, indent=4)\n",
    "\n",
    "# print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reformat_json(input_json, output_json):\n",
    "#     \"\"\"Reformats jason with a following hierarchy: \n",
    "#     from: category/task/subject/metric-value\n",
    "#     to: category/task/metric/subject-value\n",
    "#     creates output_json\n",
    "\n",
    "#     Args:\n",
    "#         input_json (_type_): _description_\n",
    "#         output_json (_type_): _description_\n",
    "#     \"\"\"\n",
    "#     with open(input_json, \"r\") as f:\n",
    "#         data = json.load(f)\n",
    "    \n",
    "#     reformatted = {\"mriqc_failed\": {}, \"mriqc_passed\": {}}\n",
    "    \n",
    "#     for category in [\"mriqc_failed\", \"mriqc_passed\"]:\n",
    "#         for task, subjects in data.get(category, {}).items():\n",
    "#             if task not in reformatted[category]:\n",
    "#                 reformatted[category][task] = {}\n",
    "            \n",
    "#             for subject, metrics in subjects.items():\n",
    "#                 for metric, value in metrics.items():\n",
    "#                     if metric not in reformatted[category][task]:\n",
    "#                         reformatted[category][task][metric] = {}\n",
    "                    \n",
    "#                     reformatted[category][task][metric][subject] = value\n",
    "    \n",
    "#     with open(output_json, \"w\") as f:\n",
    "#         json.dump(reformatted, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_json = \"quality_metrics/quality_metrics_all.json\"\n",
    "output_json = \"quality_metrics/quality_metrics_all_reformatted.json\"\n",
    "metrics_csv = \"quality_metrics/BOLD_quality_metrics.csv\"\n",
    "\n",
    "# Run functions\n",
    "# reformat_json(input_json, output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves metrics for plot functions\n",
    "# dictionary saving low, median, and high values for each metric\n",
    "thresholds = dict()\n",
    "\n",
    "# opens metrics csv (listing names and thresholds)\n",
    "with open(metrics_csv, \"r\") as f:\n",
    "    reader = csv.DictReader(f)  # Read CSV as dictionary\n",
    "    for row in reader:\n",
    "        # metric = metric name\n",
    "        metric = row[\"Metric\"]  # Get the metric name\n",
    "\n",
    "        # thresholds = dictionary with keys: metric, values: low, high, and median\n",
    "        low, high, median = float(row[\"Low\"]), float(row[\"High\"]), float(row[\"Median\"])  # Convert to floats\n",
    "        thresholds[metric] = (low, high, median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6090883276564011, -0.5924588695485542, 0.13376087267348097, -0.7552329324027326, -0.7920109797665414, -0.8122805220649598, -0.790920876600641]\n"
     ]
    }
   ],
   "source": [
    "metric = \"gsr_y\"\n",
    "values = [0.04774569720029831,0.04930886626243591,0.11757352203130722,0.03400810435414314,\n",
    "                0.030550967901945114,\n",
    "                0.028645630925893784,\n",
    "                0.030653437599539757]\n",
    "\n",
    "if metric in thresholds:\n",
    "    (low, high, median) = thresholds[metric]\n",
    "    std_dev = (high - low) / 2  # Approximate standard deviation #0.09\n",
    "    mid = (high + low) / 2\n",
    "    values = [(v - mid) / std_dev for v in values]\n",
    "\n",
    "print(values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots task-metric \n",
    "def plot_task_metric(task, metric, data, thresholds, save_dir):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        task (_type_): _description_\n",
    "        metric (_type_): _description_\n",
    "        data (_type_): _description_\n",
    "        thresholds (_type_): _description_\n",
    "        save_dir (str, optional): _description_. Defaults to \"quality_metrics/plots\".\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    subjects = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract data for both \"mriqc_failed\" and \"all_included\"\n",
    "    for category in [\"mriqc_failed\",\"mriqc_passed\"]:\n",
    "        if task in data[category] and metric in data[category][task]:\n",
    "            for subject, value in data[category][task][metric].items():\n",
    "                subjects.append(subject)\n",
    "                values.append(value)\n",
    "                categories.append(category)  # Keep track of whether it's \"mriqc_failed\" or \"all_included\"\n",
    "    \n",
    "    # Z-normalize values using Low, High, and Median from thresholds\n",
    "    if metric in thresholds:\n",
    "        (low, high, median) = thresholds[metric]\n",
    "        std_dev = (high - low) / 2  # Approximate standard deviation\n",
    "        mid = (high + low) / 2\n",
    "        values = [(v - mid) / std_dev for v in values]\n",
    "\n",
    "    # Assign colors (red if outside range, green if inside)\n",
    "    for value in values:\n",
    "        if -1 <= value <= 1:  # Within expected range\n",
    "            colors.append(\"green\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    \n",
    "    # Separate \"mriqc_failed\" from \"mriqc_passed\" in the plot\n",
    "    failed_count = sum(1 for cat in categories if cat == \"mriqc_failed\")\n",
    "    \n",
    "    fig_width = max(len(subjects) * 0.5,6)  # Store the calculated height\n",
    "    # Increase figure height\n",
    "    fig, ax = plt.subplots(figsize=(fig_width,6))\n",
    "    \n",
    "    ax.scatter(range(len(subjects)), values, c=colors, s=50)\n",
    "    # Add a horizontal separation line between failed and included\n",
    "    # if failed_count > 0:\n",
    "    ax.axvline(x=failed_count - 0.5, color=\"black\", linestyle=\"--\")\n",
    "        # if (len(values)-1 > failed_count):\n",
    "    if failed_count >=3:\n",
    "        ax.text(-0.5, 1.8, \"mriqc_failed\", fontsize=8)\n",
    "        ax.text(failed_count - 0.3, 1.8, \"mriqc_passed\", fontsize=8)\n",
    "\n",
    "    elif failed_count >0:\n",
    "        ax.text(-0.5, 1.8, \"mriqc_failed\", fontsize=8)\n",
    "        ax.text(failed_count - 0.3, 1.55, \"mriqc_passed\", fontsize=8)\n",
    "\n",
    "    else:\n",
    "        ax.text(failed_count - 0.3, 1.8, \"mriqc_passed\", fontsize=8)\n",
    "\n",
    "\n",
    "    # Set y-axis labels (subjects)\n",
    "    ax.set_yticks([-2,-1,0,1,2])\n",
    "    \n",
    "    # Add plot title and labels\n",
    "    plt.title(f\"{task} - {metric}\", fontsize=20, pad=20, y= 1)\n",
    "    plt.ylabel(\"Z-Normalized Value\", fontsize=12)\n",
    "    plt.xlabel(\"Subjects\", fontsize=12)\n",
    "    \n",
    "    # Draw shaded gray region for acceptable range (-1 to 1)\n",
    "    ax.axhspan(-1, 1, color=\"gray\", alpha=0.2)    \n",
    "    # Add small annotations for value ranges\n",
    "    \n",
    "    if values[-1] > 0:\n",
    "        ax.text(len(subjects)-0.5, -0.8, \"within\\nrange\", ha=\"right\", fontsize=8)\n",
    "    else:\n",
    "        ax.text(len(subjects)-0.5, 0.7, \"within\\nrange\", ha=\"right\", fontsize=8)\n",
    "    ax.text(len(subjects)-0.5, -1.2, \"low\",  ha=\"right\", fontsize=8)\n",
    "    ax.text(len(subjects)-0.5, 1.1, \"high\",  ha=\"right\", fontsize=8)\n",
    "\n",
    "    # Ensure x-axis ticks are visible\n",
    "    # plt.xticks(range(int(min(values)) - 1, int(max(values)) + 2))\n",
    "    plt.xticks(range(len(subjects)), subjects, rotation=45, ha='right')\n",
    "    plt.ylim(-2,2)\n",
    "\n",
    "    # Add legend\n",
    "    ax.scatter([], [], color=\"green\", label=\"In range\")\n",
    "    ax.scatter([], [], color=\"red\", label=\"Outside range\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "    # Adjust margins\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{task}-{metric}.png\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the plot function in one file to make sure it's working correctly: \n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    plot_task_metric(\"ANT\", \"dvars_vstd\", data, thresholds, save_dir=\"quality_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all combinations of task-metric plots\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f) \n",
    "    for task in TASKS:\n",
    "        # print(task)\n",
    "        for metric in list(thresholds.keys()):\n",
    "\n",
    "            # for each unique task-metric combination, plot a graph \n",
    "            # data(json file), thresholds (dictionary)\n",
    "            plot_task_metric(task, metric, data, thresholds, save_dir=\"quality_metrics/plots/task-metric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plots saved in quality_metrics/plots/task-metric/combined_task-metric_plots\n"
     ]
    }
   ],
   "source": [
    "# combine task-metric plots per task plots. All same subject plots should be on the same canvas.\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory containing the plots\n",
    "plots_dir = \"quality_metrics/plots/task-metric\"\n",
    "\n",
    "# Organize images by subject_id\n",
    "task_plots = defaultdict(list)\n",
    "\n",
    "# Find all PNG files in the directory\n",
    "png_files = glob.glob(os.path.join(plots_dir, \"*.png\"))  # Recursively get all PNGs\n",
    "\n",
    "# Group plots by subject_id\n",
    "for file in png_files:\n",
    "    filename = os.path.basename(file).removesuffix(\".png\")  # Extracts \"category-subjectid-task.png\"\n",
    "    parts = filename.split(\"-\")  # Split by '-'\n",
    "    \n",
    "    task, metric = parts[0], parts[1]  \n",
    "    task_plots[task].append((file, metric))\n",
    "\n",
    "# Generate combined plots for each subject\n",
    "output_dir = \"quality_metrics/plots/task-metric/combined_task-metric_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for task, plots in task_plots.items():\n",
    "    num_plots = len(plots)\n",
    "    cols = 3  # Limit columns to 4 for readability\n",
    "    rows = 2  # Compute rows based on number of plots\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))  # Adjust figure size\n",
    "    fig.suptitle(f\"{task} across Metrics\", fontsize=16, y = 0.95)\n",
    "\n",
    "    # Flatten axes if only one row or column\n",
    "    axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "    for ax, (file, metric) in zip(axes, sorted(plots, key=lambda x: x[1])):  # Sort by category\n",
    "        img = mpimg.imread(file)\n",
    "        ax.imshow(img)\n",
    "        # ax.set_title(f\"{task} - {metric}\", fontsize=10, y=0.95)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots if any\n",
    "    for i in range(len(plots), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Save the combined figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to fit title\n",
    "    output_path = os.path.join(output_dir, f\"{task}_across_metrics.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Combined plots saved in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-quality PDF saved at: plots_important/task-metric.pdf\n"
     ]
    }
   ],
   "source": [
    "# CREATE PDF FOR TASK-METRIC\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Directory containing the combined subject-task plots\n",
    "combined_plots_dir = \"quality_metrics/plots/task-metric/combined_task-metric_plots\"\n",
    "output_pdf = os.path.join(\"plots_important\", \"task-metric.pdf\")\n",
    "\n",
    "# Find all PNG images in the directory\n",
    "image_files = sorted(glob.glob(os.path.join(combined_plots_dir, \"*.png\")))\n",
    "\n",
    "# Create a high-quality PDF\n",
    "with PdfPages(output_pdf) as pdf:\n",
    "    for img_file in image_files:\n",
    "        img = Image.open(img_file)  # Open the image with Pillow\n",
    "        fig, ax = plt.subplots(figsize=(img.width / 100, img.height / 100), dpi=300)  # Preserve size\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\", dpi=300)  # Save figure to PDF\n",
    "        plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "print(f\"High-quality PDF saved at: {output_pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot subject task\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_subject_task(category, task, subject, data, thresholds, save_dir):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        task (_type_): _description_\n",
    "        metric (_type_): _description_\n",
    "        data (_type_): _description_\n",
    "        thresholds (_type_): _description_\n",
    "        save_dir (str, optional): _description_. Defaults to \"quality_metrics/plots\".\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    metrics = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    categories = []\n",
    "    \n",
    "\n",
    "    # Extract data for both \"mriqc_failed\" and \"all_included\"\n",
    "    # takes in quality_metrics_all (not reformatted)\n",
    "    category = category\n",
    "    if task in data[category] and subject in data[category][task]:\n",
    "        for metric, value in data[category][task][subject].items():\n",
    "            metrics.append(metric)\n",
    "            values.append(value)\n",
    "            categories.append(category)  # Keep track of whether it's \"mriqc_failed\" or \"all_included\"\n",
    "    \n",
    "    # Z-normalize values using Low, High, and Median from thresholds\n",
    "    # update the values array with normalized values.\n",
    "    for metric in metrics:\n",
    "        (low, high, median) = thresholds[metric]\n",
    "        std_dev = (high - low) / 2  # Approximate standard deviation\n",
    "        mid = (high + low) / 2\n",
    "        value_idx = metrics.index(metric)\n",
    "        values[value_idx] = (values[value_idx] - mid) / std_dev\n",
    "\n",
    "    # Assign colors (red if outside range, green if inside)\n",
    "    for value in values:\n",
    "        if -1 <= value <= 1:  # Within expected range\n",
    "            colors.append(\"green\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    \n",
    "    \n",
    "    # Increase figure height\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    ax.scatter(range(len(metrics)), values, c=colors, s=50)\n",
    "\n",
    "    # Set y-axis labels (subjects)\n",
    "    ax.set_yticks([-2, -1, 0, 1, 2])\n",
    "    \n",
    "    # Add plot title and labels\n",
    "    plt.title(f\"{subject} - {task} - {category.strip(\"mriqc_\")}\", fontsize=20, pad=20, y= 1)\n",
    "    plt.ylabel(\"Z-Normalized Value\", fontsize=12)\n",
    "    plt.xlabel(\"Metrics\", fontsize=12)\n",
    "    \n",
    "    # Draw shaded gray region for acceptable range (-1 to 1)\n",
    "    ax.axhspan(-1, 1, color=\"gray\", alpha=0.2)\n",
    "    \n",
    "    # Add small annotations for value ranges\n",
    "    len_metric = len(metrics)-1+0.1\n",
    "    if values[-1] < 0:\n",
    "        ax.text(len_metric, 0.7, \"within\\nrange\", verticalalignment='center', ha=\"right\", fontsize=8)\n",
    "    else: \n",
    "        ax.text(len_metric, -0.8, \"within\\nrange\", verticalalignment='center', ha=\"right\",fontsize=8)\n",
    "    ax.text(len_metric, -1.2, \"low\", verticalalignment='center', ha=\"right\",fontsize=8)\n",
    "    ax.text(len_metric, 1.1, \"high\", verticalalignment='center', ha=\"right\",fontsize=8)\n",
    "\n",
    "    # Ensure x-axis ticks are visible\n",
    "    # plt.xticks(range(int(min(values)) - 1, int(max(values)) + 2)\n",
    "    plt.xticks(range(6), metrics)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.scatter([], [], color=\"green\", label=\"In range\")\n",
    "    ax.scatter([], [], color=\"red\", label=\"Outside range\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.ylim(-2,2)\n",
    "    # Adjust margins\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.2)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{category.strip(\"mriqc_\")}-{subject}-{task}.png\"), dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the plot function in one file to make sure it's working correctly: \n",
    "output_json = \"quality_metrics/quality_metrics_all.json\"\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    plot_subject_task(\"mriqc_failed\", \"CCTHot\", \"s607\", data, thresholds, save_dir=\"quality_metrics/plots/subject-task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all combinations of subject-task plots\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f) \n",
    "    for category,task in data.items(): \n",
    "        for task, subject in task.items(): \n",
    "            for subject,metrics in subject.items():\n",
    "                # for each unique task-metric combination, plot a graph \n",
    "                # data(json file), thresholds (dictionary)\n",
    "                plot_subject_task(category, task, subject, data, thresholds, save_dir=\"quality_metrics/plots/subject-task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plots saved in quality_metrics/plots/subject-task/combined_subject-task_plots\n"
     ]
    }
   ],
   "source": [
    "# combine subject-task plots in a canvas per subject. All same subject plots should be on the same canvas.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory containing the plots\n",
    "plots_dir = \"quality_metrics/plots/subject-task\"\n",
    "\n",
    "# Organize images by subject_id\n",
    "subject_plots = defaultdict(list)\n",
    "\n",
    "# Find all PNG files in the directory\n",
    "png_files = glob.glob(os.path.join(plots_dir, \"*.png\"))  # Recursively get all PNGs\n",
    "\n",
    "# Group plots by subject_id\n",
    "for file in png_files:\n",
    "    filename = os.path.basename(file)  # Extracts \"category-subjectid-task.png\"\n",
    "    parts = filename.split(\"-\")  # Split by '-'\n",
    "    \n",
    "    category, subject_id, task = parts[0], parts[1], parts[2] \n",
    "    subject_plots[subject_id].append((file, category, task))\n",
    "\n",
    "# Generate combined plots for each subject\n",
    "output_dir = \"quality_metrics/plots/subject-task/combined_subject-task_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for subject_id, plots in subject_plots.items():\n",
    "    num_plots = len(plots)\n",
    "    cols = min(num_plots, 4)  # Limit columns to 4 for readability\n",
    "    rows = (num_plots + cols - 1) // cols  # Compute rows based on number of plots\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))  # Adjust figure size\n",
    "\n",
    "    fig.suptitle(f\"{subject_id} across Tasks\", fontsize=16, y= (0.92 if (len(plots)+1)//4 ==0 else 0.95))\n",
    "\n",
    "    # Flatten axes if only one row or column\n",
    "    axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "    for ax, (file, category, task) in zip(axes, sorted(plots, key=lambda x: x[1])):  # Sort by category\n",
    "        img = mpimg.imread(file)\n",
    "        ax.imshow(img)\n",
    "        # ax.set_title(f\"{category} - {task}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots if any\n",
    "    for i in range(len(plots), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Save the combined figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to fit title\n",
    "    output_path = os.path.join(output_dir, f\"{subject_id}_combined.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Combined plots saved in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plots saved in quality_metrics/plots/subject-task/combined_task-subject_plots\n"
     ]
    }
   ],
   "source": [
    "# combine task subject plots, canvas per task\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory containing the plots\n",
    "plots_dir = \"quality_metrics/plots/subject-task\"\n",
    "\n",
    "# Organize images by subject_id\n",
    "task_plots = defaultdict(list)\n",
    "\n",
    "# Find all PNG files in the directory\n",
    "png_files = glob.glob(os.path.join(plots_dir, \"*.png\"))  # Recursively get all PNGs\n",
    "\n",
    "# Group plots by subject_id\n",
    "for file in png_files:\n",
    "    filename = os.path.basename(file).removesuffix(\".png\")  # Extracts \"category-subjectid-task.png\"\n",
    "    parts = filename.split(\"-\")  # Split by '-'\n",
    "    \n",
    "    category, subject_id, task = parts[0], parts[1], parts[2] \n",
    "    task_plots[task].append((file, category, subject_id))\n",
    "\n",
    "# Generate combined plots for each subject\n",
    "output_dir = \"quality_metrics/plots/subject-task/combined_task-subject_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for task, plots in task_plots.items():\n",
    "    num_plots = len(plots)\n",
    "    cols = 4  # Limit columns to 4 for readability\n",
    "    rows = ((num_plots-1)// cols)+1  # Compute rows based on number of plots\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))  # Adjust figure size\n",
    "    fig.suptitle(f\"{task} across Subjects\", fontsize=16, y= (0.9))\n",
    "\n",
    "    # Flatten axes if only one row or column\n",
    "    axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "    for ax, (file, category, subject) in zip(axes, sorted(plots, key=lambda x: (x[1], x[2]))):          \n",
    "        img = mpimg.imread(file)\n",
    "        ax.imshow(img)\n",
    "        # ax.set_title(f\"{category} - {subject}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots if any\n",
    "    for i in range(len(plots), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Save the combined figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])  # Adjust layout to fit title\n",
    "    output_path = os.path.join(output_dir, f\"{task}_combined.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Combined plots saved in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-quality PDF saved at: plots_important/subject_task.pdf\n"
     ]
    }
   ],
   "source": [
    "# CREATE PDF USING CANVAS\n",
    "# change the directories to create the pdfs\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Directory containing the combined subject-task plots\n",
    "combined_plots_dir = \"quality_metrics/plots/subject-task/combined_subject-task_plots\"\n",
    "output_pdf = os.path.join(\"plots_important/subject_task.pdf\")\n",
    "\n",
    "# Find all PNG images in the directory\n",
    "image_files = sorted(glob.glob(os.path.join(combined_plots_dir, \"*.png\")))\n",
    "\n",
    "# Create a high-quality PDF\n",
    "with PdfPages(output_pdf) as pdf:\n",
    "    for img_file in image_files:\n",
    "        img = Image.open(img_file)  # Open the image with Pillow\n",
    "        fig, ax = plt.subplots(figsize=(img.width / 100, img.height / 100), dpi=300)  # Preserve size\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\", dpi=300)  # Save figure to PDF\n",
    "        plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "print(f\"High-quality PDF saved at: {output_pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reformat json for subject-metrics plotting\n",
    "# # Input and output file paths\n",
    "# input_json = \"quality_metrics/quality_metrics_all_reformatted.json\"\n",
    "# output_json = \"quality_metrics/quality_metrics_reformatted_subject-metrics.json\"\n",
    "\n",
    "# # Load the original JSON data\n",
    "# with open(input_json, \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Reformat the data\n",
    "# reformatted_data = {}\n",
    "\n",
    "# for category, tasks in data.items():\n",
    "#     for task, metrics in tasks.items():\n",
    "#         for metric, subjects in metrics.items():\n",
    "#             for subject, value in subjects.items():\n",
    "#                 if category not in reformatted_data:\n",
    "#                     reformatted_data[category] = {}\n",
    "#                 if subject not in reformatted_data[category]:\n",
    "#                     reformatted_data[category][subject] = {}\n",
    "#                 if metric not in reformatted_data[category][subject]:\n",
    "#                     reformatted_data[category][subject][metric] = {}\n",
    "                \n",
    "#                 reformatted_data[category][subject][metric][task] = value\n",
    "\n",
    "# # Ensure the output directory exists\n",
    "# os.makedirs(\"quality_metrics\", exist_ok=True)\n",
    "\n",
    "# # Save the reformatted JSON\n",
    "# with open(output_json, \"w\") as f:\n",
    "#     json.dump(reformatted_data, f, indent=4)\n",
    "\n",
    "# print(f\"Reformatted JSON saved to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots subject-metric\n",
    "def plot_subject_metric(subject, metric, data, thresholds, save_dir):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        task (_type_): _description_\n",
    "        metric (_type_): _description_\n",
    "        data (_type_): _description_\n",
    "        thresholds (_type_): _description_\n",
    "        save_dir (str, optional): _description_. Defaults to \"quality_metrics/plots\".\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    tasks = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    categories = []\n",
    "    \n",
    "    # Extract data for both \"mriqc_failed\" and \"all_included\"\n",
    "    for category in [\"mriqc_failed\",\"mriqc_passed\"]:\n",
    "        if subject in data[category] and metric in data[category][subject]:\n",
    "            for task, value in data[category][subject][metric].items():\n",
    "                tasks.append(task)\n",
    "                values.append(value)\n",
    "                categories.append(category)  # Keep track of whether it's \"mriqc_failed\" or \"all_included\"\n",
    "    \n",
    "    # Z-normalize values using Low, High, and Median from thresholds\n",
    "    if metric in thresholds:\n",
    "        (low, high, median) = thresholds[metric]\n",
    "        std_dev = (high - low) / 2  # Approximate standard deviation\n",
    "        mid = (high + low) / 2\n",
    "        values = [(v - mid) / std_dev for v in values]\n",
    "\n",
    "    # Assign colors (red if outside range, green if inside)\n",
    "    for value in values:\n",
    "        if -1 <= value <= 1:  # Within expected range\n",
    "            colors.append(\"green\")\n",
    "        else:\n",
    "            colors.append(\"red\")\n",
    "    \n",
    "    # Separate \"mriqc_failed\" from \"mriqc_passed\" in the plot\n",
    "    failed_count = sum(1 for cat in categories if cat == \"mriqc_failed\")\n",
    "    passed_count = sum(1 for cat in categories if cat == \"mriqc_passed\")\n",
    "\n",
    "    fig_width = max(len(tasks) * 0.5,8)  # Store the calculated height\n",
    "    # Increase figure height\n",
    "    fig, ax = plt.subplots(figsize=(fig_width,6))\n",
    "    \n",
    "    ax.scatter(range(len(tasks)), values, c=colors, s=50)\n",
    "    # Add a horizontal separation line between failed and included\n",
    "    # if failed_count > 0\n",
    "        # if (len(values)-1 > failed_count):\n",
    "    if (failed_count > 0) and (passed_count) > 0:\n",
    "        ax.axvline(x=failed_count - 0.5, color=\"black\", linestyle=\"--\")\n",
    "    \n",
    "    if failed_count >=4:\n",
    "        ax.text(-.15, -1.9, \"mriqc_failed\", fontsize=8)\n",
    "        if passed_count >= 1:\n",
    "            ax.text(failed_count - 0.3, -1.9, \"mriqc_passed\", fontsize=8)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    elif failed_count >=1:\n",
    "        ax.text(0, -1.8, \"mriqc_failed\", fontsize=8)\n",
    "        if passed_count >= 1:\n",
    "            ax.text(failed_count - 0.3, -1.9, \"mriqc_passed\", fontsize=8)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        ax.text(0, -1.9, \"mriqc_passed\", fontsize=8)\n",
    "\n",
    "\n",
    "    # Set y-axis labels (subjects)\n",
    "    ax.set_yticks([-2,-1,0,1,2])\n",
    "    \n",
    "    # Add plot title and labels\n",
    "    plt.title(f\"{subject} - {metric}\", fontsize=20, pad=20, y= 1)\n",
    "    plt.ylabel(\"Z-Normalized Value\", fontsize=12)\n",
    "    plt.xlabel(\"Tasks\", fontsize=12, loc=\"center\")\n",
    "    \n",
    "    # Draw shaded gray region for acceptable range (-1 to 1)\n",
    "    ax.axhspan(-1, 1, color=\"gray\", alpha=0.2)    \n",
    "    # Add small annotations for value ranges\n",
    "    if values[-1] > 0:\n",
    "        ax.text(len(tasks)-1, -0.8, \"within\\nrange\", ha=\"center\", fontsize=8)\n",
    "    else:\n",
    "        ax.text(len(tasks)-1, 0.7, \"within\\nrange\", ha=\"center\", fontsize=8)\n",
    "    ax.text(len(tasks)-1, -1.2, \"low\",  ha=\"center\", fontsize=8)\n",
    "    ax.text(len(tasks)-1, 1.1, \"high\",  ha=\"center\", fontsize=8)\n",
    "\n",
    "    # Ensure x-axis ticks are visible\n",
    "    # plt.xticks(range(int(min(values)) - 1, int(max(values)) + 2))\n",
    "    plt.xticks(range(len(tasks)), tasks, rotation=45, ha='right')\n",
    "    plt.ylim(-2,2)\n",
    "\n",
    "    # Add legend\n",
    "    ax.scatter([], [], color=\"green\", label=\"In range\")\n",
    "    ax.scatter([], [], color=\"red\", label=\"Outside range\")\n",
    "\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout() # Adjusts layout to prevent labels from being clipped\n",
    "\n",
    "    # Adjust margins\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.8, bottom=0.3)\n",
    "    plt.margins(x=0.05) \n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(save_dir, f\"{subject}-{metric}.png\"), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = \"quality_metrics/quality_metrics_reformatted_subject-metrics.json\"\n",
    "# try the plot function in one file to make sure it's working correctly: \n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f)  # Use json.load() instead of json.loads()\n",
    "    plot_subject_metric(\"s608\", \"dvars_vstd\", data, thresholds, save_dir=\"quality_metrics/plots/subject-metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = \"quality_metrics/quality_metrics_reformatted_subject-metrics.json\"\n",
    "\n",
    "with open(output_json, \"r\") as f:\n",
    "    data = json.load(f) \n",
    "    for category, subjects in data.items():  # subjects is a dict\n",
    "        for subject, metrics in subjects.items():  # subject is now the key (name)\n",
    "            for metric, tasks in metrics.items():  # tasks is a dict\n",
    "                # for each unique subject-metric combination, plot a graph \n",
    "                # data(json file), thresholds (dictionary)\n",
    "                plot_subject_metric(subject, metric, data, thresholds, save_dir=\"quality_metrics/plots/subject-metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plots saved in quality_metrics/plots/subject-metric/combined_subject-metric_plots\n"
     ]
    }
   ],
   "source": [
    "# combine subject-metric plots in one canvas. All same subject plots should be on the same canvas.\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory containing the plots\n",
    "plots_dir = \"quality_metrics/plots/subject-metric\"\n",
    "\n",
    "# Organize images by subject_id\n",
    "subject_plots = defaultdict(list)\n",
    "\n",
    "# Find all PNG files in the directory\n",
    "png_files = glob.glob(os.path.join(plots_dir, \"*.png\"))  # Recursively get all PNGs\n",
    "\n",
    "# Group plots by subject_id\n",
    "for file in png_files:\n",
    "    filename = os.path.basename(file).removesuffix(\".png\")  # Extracts \"category-subjectid-task.png\"\n",
    "    parts = filename.split(\"-\")  # Split by '-'\n",
    "    \n",
    "    subject, metric = parts[0], parts[1]  \n",
    "    subject_plots[subject].append((file, metric))\n",
    "\n",
    "# Generate combined plots for each subject\n",
    "output_dir = \"quality_metrics/plots/subject-metric/combined_subject-metric_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for subject, plots in subject_plots.items():\n",
    "    num_plots = len(plots)\n",
    "    cols = 3\n",
    "    rows = 2\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))  # Adjust figure size\n",
    "    fig.suptitle(f\"{subject} across Metrics\", fontsize=16, y=92)\n",
    "\n",
    "    # Flatten axes if only one row or column\n",
    "    axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "    for ax, (file, metric) in zip(axes, sorted(plots, key=lambda x: x[1])): \n",
    "        img = mpimg.imread(file)\n",
    "        ax.imshow(img)\n",
    "        # ax.set_title(f\"{subject} - {metric}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots if any\n",
    "    for i in range(len(plots), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Save the combined figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "    output_path = os.path.join(output_dir, f\"{subject}_combined.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Combined plots saved in {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-quality PDF saved at: plots_important/subject-metric.pdf\n"
     ]
    }
   ],
   "source": [
    "# CREATE PDF FOR TASK-METRIC\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Directory containing the combined subject-task plots\n",
    "combined_plots_dir = \"quality_metrics/plots/subject-metric/combined_subject-metric_plots\"\n",
    "output_pdf = os.path.join(\"plots_important\", \"subject-metric.pdf\")\n",
    "\n",
    "# Find all PNG images in the directory\n",
    "image_files = sorted(glob.glob(os.path.join(combined_plots_dir, \"*.png\")))\n",
    "\n",
    "# Create a high-quality PDF\n",
    "with PdfPages(output_pdf) as pdf:\n",
    "    for img_file in image_files:\n",
    "        img = Image.open(img_file)  # Open the image with Pillow\n",
    "        fig, ax = plt.subplots(figsize=(img.width / 100, img.height / 100), dpi=300)  # Preserve size\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\", dpi=300)  # Save figure to PDF\n",
    "        plt.close(fig)  # Close figure to free memory\n",
    "\n",
    "print(f\"High-quality PDF saved at: {output_pdf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
